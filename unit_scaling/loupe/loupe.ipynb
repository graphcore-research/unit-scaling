{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/charlieb/Projects/graphcore/unit-scaling\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/charlieb/Projects/graphcore/unit-scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from subprocess import Popen\n",
    "\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from typing import *\n",
    "import matplotlib\n",
    "\n",
    "from unit_scaling.analysis import example_batch, graph_to_dataframe, prune_non_float_tensors, prune_same_scale_tensors\n",
    "from unit_scaling.transforms import track_scales\n",
    "\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, LlamaConfig\n",
    "\n",
    "from torch.fx.graph import Graph\n",
    "import logging\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def connect_graph_inputs(inter_graph_connections, graph, previous_graphs):\n",
    "    def find_output_node(input_node):\n",
    "        graph_idx = len(previous_graphs) - 1\n",
    "        for prev_graph in reversed(previous_graphs):\n",
    "            for output_node in reversed(prev_graph.nodes):\n",
    "                out_users = list(output_node.users.keys())\n",
    "                if len(output_node.users) == 1 and any(ou.op == \"output\" for ou in out_users) and input_node.meta[\"metrics\"] == output_node.meta[\"metrics\"]:\n",
    "                    logger.info(\"connecting nodes across graph-break: %s %s\", input_node.meta[\"clean_name\"], output_node.meta[\"clean_name\"])\n",
    "                    inter_graph_connections[input_node] = (output_node, graph_idx)\n",
    "                    input_node.meta[\"df_drop\"] = True\n",
    "                    return\n",
    "            graph_idx -= 1\n",
    "    \n",
    "    for input_node in graph.nodes:\n",
    "        if input_node.op == \"placeholder\":\n",
    "            find_output_node(input_node)\n",
    "\n",
    "\n",
    "def tidy_data(\n",
    "    graphs: List[Graph],\n",
    "    prune_same_scale: bool = True,\n",
    ") -> matplotlib.axes.Axes:\n",
    "    df = pd.DataFrame()\n",
    "    inter_graph_connections = {}\n",
    "    pruned_graphs = []\n",
    "    for graph_idx, graph in enumerate(graphs):\n",
    "        # for nn in graph.nodes:\n",
    "        #     print(\"nn\", nn.meta)\n",
    "        # graph.print_tabular()\n",
    "        graph = prune_non_float_tensors(graph)\n",
    "        if prune_same_scale:\n",
    "            graph = prune_same_scale_tensors(graph)\n",
    "        connect_graph_inputs(inter_graph_connections, graph, pruned_graphs)\n",
    "        pruned_graphs.append(graph)\n",
    "        graph_df = graph_to_dataframe(graph)\n",
    "        graph_df[\"graph_idx\"] = str(graph_idx)\n",
    "        df = pd.concat([df, graph_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def gen_data(\n",
    "    model: nn.Module,\n",
    "    tokenizer: \"PreTrainedTokenizerBase\",\n",
    "    batch_size: int,\n",
    "    seq_len: int,\n",
    "    backward: bool = True,\n",
    "    dataset_path: str = \"wikitext\",\n",
    "    dataset_name: str = \"wikitext-103-v1\",\n",
    "    **plot_kwargs: Any,\n",
    ") -> matplotlib.axes.Axes:\n",
    "    inputs, attn_mask, labels = example_batch(\n",
    "        tokenizer, batch_size, seq_len, dataset_path, dataset_name\n",
    "    )\n",
    "    tracked_model = track_scales(model.to(\"cpu\"))\n",
    "    out = tracked_model(input_ids=inputs, attention_mask=attn_mask, labels=labels)  # TODO: handle\n",
    "    if backward:\n",
    "        out.loss.backward()\n",
    "    graphs = tracked_model.scales_graphs()  # type: ignore[operator]\n",
    "    return graphs\n",
    "\n",
    "\n",
    "def write_data(df):\n",
    "    import os\n",
    "    os.chdir(\"unit_scaling/loupe\")\n",
    "    display(df)\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    df[\"Misc\"] = df[\"Misc\"] ** -1.0\n",
    "\n",
    "    dir_path = Path(\".loupe_data\")\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = Path(\".loupe_data\") / str(datetime.now())\n",
    "    df.to_csv(file_path, index=False)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def launch_server(file_path):\n",
    "    p = Popen([\"python\", \"-m\", \"http.server\"])\n",
    "    webbrowser.open(\n",
    "        f\"http://localhost:8000/index.html?file_path={file_path}\"\n",
    "    )  # TODO: get any free port\n",
    "    p.wait()  # TODO: graceful interrupt\n",
    "    print(\"goodbye\")\n",
    "\n",
    "\n",
    "def run():\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(\"hf-internal-testing/llama-tokenizer\")\n",
    "    config = LlamaConfig(\n",
    "        vocab_size=len(tokenizer),\n",
    "        hidden_size=16,\n",
    "        intermediate_size=4*3,\n",
    "        num_hidden_layers=6,\n",
    "        num_attention_heads=8,\n",
    "        initializer_range=1.0,\n",
    "    )\n",
    "    model = LlamaForCausalLM(config)\n",
    "    data = gen_data(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        batch_size=2,\n",
    "        seq_len=7,\n",
    "    )\n",
    "    data = tidy_data(data)\n",
    "    file_path = write_data(data)\n",
    "    launch_server(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'unit_scaling/loupe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m run()\n",
      "\u001b[1;32m/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m data \u001b[39m=\u001b[39m gen_data(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     model,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     tokenizer,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     seq_len\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m data \u001b[39m=\u001b[39m tidy_data(data)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m file_path \u001b[39m=\u001b[39m write_data(data)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m launch_server(file_path)\n",
      "\u001b[1;32m/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_data\u001b[39m(df):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     os\u001b[39m.\u001b[39;49mchdir(\u001b[39m\"\u001b[39;49m\u001b[39munit_scaling/loupe\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     display(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/charlieb/Projects/graphcore/unit-scaling/unit_scaling/loupe/loupe.ipynb#W1sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'unit_scaling/loupe'"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
